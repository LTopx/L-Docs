# Azure OpenAI API Key Configuration

You can use L-GPT without logging in, but you must configure it to use your own API Key.

### API Key

Configure your own Azure OpenAI API Key. [Get API Key here](https://portal.azure.com/)

- If not configured, the API Key service provided by the author must be used after logging in.

### Resource Name

Unlike the official configuration for OpenAI API, when creating the Azure OpenAI Service, you need to first create a separate resource instance name of your own. Therefore, when configuring, you need to fill in the name you created.

- As the service is provided by Azure, it is inevitable that it is a bit cumbersome, and the Resource Name must be configured according to the requirements.
- Only one Resource Name needs to be created, because gpt-3.5/gpt-4(if permission) can be deployed under the same Resource Name simultaneously.

![Resource Name](/api-key-configure/azure/resource-name.png)

### Deployments

After creating the Resource Name, you can start deploying the language model that you need.

- Select a model: You can choose the model version you want to deploy, such as gpt-35-turbo, gpt-4, etc.
- Deployment name: Name the model you want to create.
  - Note: Azure stipulates that the Deployment name cannot contain special characters such as "\_" and ".", so your name cannot be the same as the official OpenAI model name. For example, a name like gpt-3.5-turbo is not allowed.

![Deployments](/api-key-configure/azure/deployments.png)

### L-GPT Configuration

After creating the Resource Name and Deployments, you can configure them on L-GPT. L-GPT provides three commonly used versions of Azure OpenAI models: gpt-3.5/gpt-4/gpt-4 32k. You just need to fill in your named Deployname in the corresponding version.

For example, if you have created a model version named gpt-4-32k with the name lgpt-4-32k, you just need to click on the Tag label for the "gpt-4-32k" section, and in the Edit deployment pop-up box, enter lgpt-4-32k.

![configure-1](/api-key-configure/azure/configure-1.png)

![configure-2](/api-key-configure/azure/configure-2.png)

### Temperature

Same configuration as OpenAI.

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

This configuration has been simplified in L-GPT, providing only three modes to choose from: Deterministic/Neutral/Random. You can adjust this parameter according to your own needs.

### Max Tokens

Same configuration as OpenAI.

> In L-GPT, the max tokens are set to 2000 by default.

The maximum number of tokens to generate in the chat completion.

The total length of input tokens and generated tokens is limited by the model's context length.

### Full configuration

![Azure OpenAI API Key](/api-key-configure/azure/configure.png)
